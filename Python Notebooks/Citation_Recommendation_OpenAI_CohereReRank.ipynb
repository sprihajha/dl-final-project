{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6GFl6Vj8FRW"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH3jyA5M1Dsh",
    "outputId": "d9041be2-277a-4c04-d8a3-e55cd1aaff27"
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install pinecone-client\n",
    "!pip install openai\n",
    "!pip install tiktoken\n",
    "!pip install chromadb\n",
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjW7Y7oT8btx"
   },
   "source": [
    "## Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZmA_Rje8grG",
    "outputId": "4821ad06-dba9-44c4-a892-a8a4dd92025c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pinecone\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone, Chroma\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZunzDAY88i-_"
   },
   "source": [
    "## Set api key and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sG-5d1MC8lom",
    "outputId": "b32b4351-489b-497f-f754-4ed38396e807"
   },
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"PINECONE_API_KEY\"\n",
    "PINECONE_API_ENV = \"PINECONE_API_ENV\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "os.environ[\"COHERE_API_KEY\"] = \"COHERE_API_KEY\"\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_API_ENV,\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "llms = OpenAIChat(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "index_name = \"citation-recommendation\"\n",
    "\n",
    "top_k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8GfB7HE8sax"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohMWjZ0-8p2b",
    "outputId": "d4cd744f-eacb-46fc-f9cd-06b7d334027a"
   },
   "outputs": [],
   "source": [
    "papers_file_path = '/content/drive/MyDrive/data/custom/papers.json'\n",
    "contexts_file_path = '/content/drive/MyDrive/data/custom/contexts.json'\n",
    "test_file_path = '/content/drive/MyDrive/data/custom/test.json'\n",
    "train_file_path = '/content/drive/MyDrive/data/custom/train.json'\n",
    "val_file_path = '/content/drive/MyDrive/data/custom/val.json'\n",
    "\n",
    "papers_data = json.load(open(papers_file_path, 'r'))\n",
    "contexts_data = json.load(open(contexts_file_path, 'r'))\n",
    "test_data = json.load(open(test_file_path, 'r'))\n",
    "train_data = json.load(open(train_file_path, 'r'))\n",
    "val_data = json.load(open(val_file_path, 'r'))\n",
    "\n",
    "query = contexts_data[val_data[0]['context_id']]['masked_text']\n",
    "print(f'Query: {query}')\n",
    "\n",
    "true_id = val_data[0]['positive_ids'][0]\n",
    "print(f'True id: {true_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPHuqVsX9PfB"
   },
   "source": [
    "## Create initial trained docsearch using just the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jnb-WdR09Qo_"
   },
   "outputs": [],
   "source": [
    "papers = []\n",
    "papers_key = []\n",
    "\n",
    "for key in papers_data:\n",
    "    paper = papers_data[key]\n",
    "    doc_number = key\n",
    "    paper_content = paper['title'] + '\\n' + paper['abstract']\n",
    "    metadata = {'source': key}\n",
    "    papers.append(Document(page_content=paper_content, metadata=metadata))\n",
    "    papers_key.append(key)\n",
    "\n",
    "papers_texts = text_splitter.split_documents(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItBFYr9_eBu0"
   },
   "source": [
    "## Create Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8f7Zoz5eF2G"
   },
   "outputs": [],
   "source": [
    "pinecone.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536,\n",
    "    metric=\"cosine\",\n",
    "    pods=1,\n",
    "    replicas=1,\n",
    "    pod_type=\"s1.x1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yuQS1d-9VSL"
   },
   "source": [
    "## Retrain docsearch using train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pB2yFNN9YOy",
    "outputId": "ed764ae1-aaad-40e3-d604-1dd88e80c627"
   },
   "outputs": [],
   "source": [
    "for key in train_data:\n",
    "    context_id = key['context_id']\n",
    "    positive_id = key['positive_ids'][0]\n",
    "    if positive_id not in papers_key:\n",
    "        paper_content = contexts_data[context_id]['masked_text']\n",
    "        metadata = {'source': positive_id}\n",
    "        papers.append(Document(page_content=paper_content, metadata=metadata))\n",
    "    else:\n",
    "        for paper in papers:\n",
    "            if paper.metadata['source'] == positive_id:\n",
    "                paper_content = paper.page_content + '\\n' + contexts_data[context_id]['masked_text']\n",
    "                paper.page_content = paper_content\n",
    "\n",
    "papers_texts = text_splitter.split_documents(papers)\n",
    "\n",
    "docsearch = Pinecone.from_texts(\n",
    "    texts=[t.page_content for t in papers_texts],\n",
    "    embedding=embeddings,\n",
    "    metadatas=[t.metadata for t in papers_texts],\n",
    "    index_name=index_name,\n",
    ").as_retriever(search_kwargs={\"k\": 100})\n",
    "\n",
    "compressor = CohereRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=docsearch)\n",
    "\n",
    "print('Trained docsearch')\n",
    "\n",
    "hit_list = []\n",
    "\n",
    "for key in test_data[:100]:\n",
    "    context_id = key['context_id']\n",
    "    positive_id = key['positive_ids'][0]\n",
    "    query = contexts_data[context_id]['masked_text']\n",
    "    compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "    if len(compressed_docs) >= 10:\n",
    "      candidate_ids = [doc.metadata['source'] for doc in compressed_docs[0:9]]\n",
    "    else:\n",
    "      candidate_ids = [doc.metadata['source'] for doc in compressed_docs]\n",
    "    hit_list.append(positive_id in candidate_ids)\n",
    "\n",
    "\n",
    "print(\"The average recall@%d: %.4f\" % (top_k, np.mean(hit_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqdLJUNt9lbA"
   },
   "source": [
    "## Delete Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwRoeEMy9oGM"
   },
   "outputs": [],
   "source": [
    "pinecone.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
